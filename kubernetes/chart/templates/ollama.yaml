{{ if .Values.ollama.enabled }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-ollama
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Release.Name }}-ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ .Release.Name }}-ollama
  template:
    metadata:
      name: {{ .Release.Name }}-ollama
      namespace: {{ .Release.Namespace }}
      labels:
        app: {{ .Release.Name }}-ollama
    spec:
      restartPolicy: Always
      containers:
        - name: {{ .Release.Name }}-ollama
          image: "{{ .Values.ollama.image.name }}:{{ .Values.ollama.image.tag }}"
          imagePullPolicy: {{ .Values.ollama.image.policy }}
          ports:
            - containerPort: 11434
              name: llm
              protocol: TCP
          lifecycle:
            postStart:
              exec:
                command: ["/bin/sh", "-c", "ollama pull llama3 && touch /tmp/ollama-llama3-downloaded"]
          readinessProbe:
            exec:
              command: ["/bin/sh", "-c", "test -f /tmp/ollama-llama3-downloaded"]
            initialDelaySeconds: 5
            periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-ollama
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Release.Name }}-ollama
spec:
    ports:
      - name: llm
        port: {{ .Values.ollama.port }}
        targetPort: llm
    selector:
        app: {{ .Release.Name }}-ollama
---
{{ end }}
